{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### This notebook fits an Recurring Neural Network over Headlines dataset for sarcasm detection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.sparse import hstack\n",
    "from normalizer import Normalizer\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.device = tf.device(\"gpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's set our envoringment to GPU!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the dataset:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_json(\"../dataset/Sarcasm_Headlines_Dataset.json\", lines = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Explore the data:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/versace-b...</td>\n",
       "      <td>former versace store clerk sues over secret 'b...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/roseanne-...</td>\n",
       "      <td>the 'roseanne' revival catches up to our thorn...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>https://www.huffingtonpost.com/entry/jk-rowlin...</td>\n",
       "      <td>j.k. rowling wishes snape happy birthday in th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        article_link  \\\n",
       "0  https://www.huffingtonpost.com/entry/versace-b...   \n",
       "1  https://www.huffingtonpost.com/entry/roseanne-...   \n",
       "2  https://local.theonion.com/mom-starting-to-fea...   \n",
       "3  https://politics.theonion.com/boehner-just-wan...   \n",
       "4  https://www.huffingtonpost.com/entry/jk-rowlin...   \n",
       "\n",
       "                                            headline  is_sarcastic  \n",
       "0  former versace store clerk sues over secret 'b...             0  \n",
       "1  the 'roseanne' revival catches up to our thorn...             0  \n",
       "2  mom starting to fear son's web series closest ...             1  \n",
       "3  boehner just wants wife to listen, not come up...             1  \n",
       "4  j.k. rowling wishes snape happy birthday in th...             0  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 26709 entries, 0 to 26708\n",
      "Data columns (total 3 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   article_link  26709 non-null  object\n",
      " 1   headline      26709 non-null  object\n",
      " 2   is_sarcastic  26709 non-null  int64 \n",
      "dtypes: int64(1), object(2)\n",
      "memory usage: 626.1+ KB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if the datatset is balanced?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14985"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data[\"is_sarcastic\"]==0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11724"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data.loc[data[\"is_sarcastic\"]==1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The dataset is unbalanced let's balance it!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>article_link</th>\n",
       "      <th>headline</th>\n",
       "      <th>is_sarcastic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>https://local.theonion.com/mom-starting-to-fea...</td>\n",
       "      <td>mom starting to fear son's web series closest ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>https://politics.theonion.com/boehner-just-wan...</td>\n",
       "      <td>boehner just wants wife to listen, not come up...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>https://politics.theonion.com/top-snake-handle...</td>\n",
       "      <td>top snake handler leaves sinking huckabee camp...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>https://entertainment.theonion.com/nuclear-bom...</td>\n",
       "      <td>nuclear bomb detonates during rehearsal for 's...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>https://www.theonion.com/cosby-lawyer-asks-why...</td>\n",
       "      <td>cosby lawyer asks why accusers didn't come for...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         article_link  \\\n",
       "2   https://local.theonion.com/mom-starting-to-fea...   \n",
       "3   https://politics.theonion.com/boehner-just-wan...   \n",
       "8   https://politics.theonion.com/top-snake-handle...   \n",
       "15  https://entertainment.theonion.com/nuclear-bom...   \n",
       "16  https://www.theonion.com/cosby-lawyer-asks-why...   \n",
       "\n",
       "                                             headline  is_sarcastic  \n",
       "2   mom starting to fear son's web series closest ...             1  \n",
       "3   boehner just wants wife to listen, not come up...             1  \n",
       "8   top snake handler leaves sinking huckabee camp...             1  \n",
       "15  nuclear bomb detonates during rehearsal for 's...             1  \n",
       "16  cosby lawyer asks why accusers didn't come for...             1  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sarcastic_data = data.loc[data[\"is_sarcastic\"]==1][:500]\n",
    "nonsarcastic_data = data.loc[data[\"is_sarcastic\"]==0][:500]\n",
    "\n",
    "data = pd.concat([sarcastic_data, nonsarcastic_data])\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now the dataset is balanced."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=[\"article_link\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seperate the labels from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data[\"headline\"]\n",
    "y = data[\"is_sarcastic\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now using the Normalization package that we created before, let's vectorize the text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Trying to create a sparse matrix for text, using an instance of TfIdf_vectorizer\n",
      "[INFO] Extracting columns containing text from dataframe.\n",
      "[INFO] Successfully extracted text columns from the dataset.\n",
      "headline\n",
      "[INFO] Applying Normalization over text:\n",
      "[INFO]       - Converting Text into lower case for caseconsistency.\n",
      "[INFO]       - Extracting only words containing alphabets.\n",
      "[INFO] Text Normalization is now complete.\n",
      "[INFO] Fitting the vecotirzer to given text.\n",
      "[INFO] Transforming the text into a sparse matrix.\n",
      "[INFO] Sparse Matrix has been successfully created over the text given as input.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<1000x4182 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 9478 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_matrix = Normalizer().vectorize(pd.DataFrame({\"headline\": X}))\n",
    "X_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's split the set into validation and train set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_Test, y_train, y_test = train_test_split(X_matrix, y, test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the necessary datasets ready let's fit an RNN to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "rnn = keras.Sequential([\n",
    "    keras.layers.LSTM(128, activation='relu', input_shape=(X_train.shape[1], 1), return_sequences=True),\n",
    "    keras.layers.Dense(64, activation='relu'),\n",
    "    keras.layers.Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile the RNN model\n",
    "rnn.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2/2 [==============================] - 128s 95s/step - loss: 0.6932 - accuracy: 0.4880\n",
      "Epoch 2/10\n",
      "2/2 [==============================] - 198s 132s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 3/10\n",
      "2/2 [==============================] - 232s 137s/step - loss: 0.6931 - accuracy: 0.5059\n",
      "Epoch 4/10\n",
      "2/2 [==============================] - 256s 147s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 5/10\n",
      "2/2 [==============================] - 269s 152s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 6/10\n",
      "2/2 [==============================] - 282s 159s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 7/10\n",
      "2/2 [==============================] - 281s 155s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 8/10\n",
      "2/2 [==============================] - 280s 154s/step - loss: 0.6932 - accuracy: 0.5000\n",
      "Epoch 9/10\n",
      "2/2 [==============================] - 284s 156s/step - loss: 0.6931 - accuracy: 0.5000\n",
      "Epoch 10/10\n",
      "2/2 [==============================] - 288s 159s/step - loss: 0.6931 - accuracy: 0.5000\n"
     ]
    }
   ],
   "source": [
    "history = rnn.fit(X_train.toarray(), y_train, epochs=10, batch_size=512)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
